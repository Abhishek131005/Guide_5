# --- Step 1: Import Libraries and Load Data ---

import pandas as pd
import matplotlib.pyplot as plt
from google.colab import files
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# This line will open an "Upload" button for you to choose your file
print("Please upload your dataset (CSV file):")
uploaded = files.upload()

# Get the name of the file you just uploaded
file_name = list(uploaded.keys())[0]

# Read the CSV file into a pandas DataFrame
df = pd.read_csv(file_name)

print(f"\nSuccessfully loaded '{file_name}'")
print("----------------------------------------")


# --- Step 2: Data Inspection ---
# We look at the data to identify our features (X) and target (y).

print("Step 2: Data Inspection")
print("First 5 rows of the data:")
print(df.head())

print("\nColumn names and data types:")
df.info()
print("\nThis step is important to identify the TARGET column.")
print("----------------------------------------")


# --- Step 3: Data Preprocessing ---

print("Step 3: Data Preprocessing")

# !!! IMPORTANT: YOU MUST EDIT THIS LINE !!!
# Change 'YOUR_TARGET_COLUMN_NAME_HERE' to the actual name of your target column.
# This is the column you want to predict (e.g., 'Species', 'Purchased', 'Diagnosis').
TARGET_COLUMN = 'REPLACE WITH YOUR TARGET COLUMN'

# Check if the target column exists
if TARGET_COLUMN not in df.columns:
    print(f"Error: Target column '{TARGET_COLUMN}' not found in the dataset.")
    print("Please edit the 'TARGET_COLUMN' variable in the code.")
else:
    print(f"Target (y) column selected: {TARGET_COLUMN}")

    # --- 3a. Handle Missing Data (Simple) ---
    # Fill missing numerical data with the average (mean)
    for col in df.select_dtypes(include=['float64', 'int64']).columns:
        df[col] = df[col].fillna(df[col].mean())

    # Fill missing categorical (text) data with the most common value (mode)
    for col in df.select_dtypes(include=['object']).columns:
        df[col] = df[col].fillna(df[col].mode()[0])

    print("Missing data has been handled.")

    # --- 3b. Separate Features (X) and Target (y) ---
    X = df.drop(TARGET_COLUMN, axis=1)
    y = df[TARGET_COLUMN]

    # --- 3c. Encode Categorical Data ---
    # Convert all text feature columns (X) into numbers using One-Hot Encoding
    X = pd.get_dummies(X)
    print("Features (X) have been one-hot encoded.")

    # Convert the target column (y) into numbers using Label Encoding
    # This is needed if y is text (e.g., "Yes", "No", "Spam")
    if y.dtype == 'object':
        le = LabelEncoder()
        y = le.fit_transform(y)
        print("Target (y) has been label encoded.")

    print("\nPreprocessed Features (X) - First 5 rows:")
    print(X.head())
    print("\nPreprocessed Target (y) - First 5 values:")
    # Check if y is a pandas Series before calling .head()
    if isinstance(y, pd.Series):
      print(y.head())
    else:
      # If y is a numpy array, print the first 5 elements
      print(y[:5])
    print("----------------------------------------")


    # --- Step 4: Split Data into Training and Testing Sets ---

    print("Step 4: Splitting data into Train and Test sets")
    # We use 70% of the data for training and 30% for testing
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    print(f"Training set size: {X_train.shape[0]} rows")
    print(f"Testing set size: {X_test.shape[0]} rows")
    print("----------------------------------------")


    # --- Step 5: Build and Train the Decision Tree Model ---

    print("Step 5: Building and Training the Decision Tree")

    # Initialize the model.
    # criterion='entropy' uses information gain to make splits.
    model = DecisionTreeClassifier(criterion='entropy', random_state=42)

    # Train the model on the training data
    model.fit(X_train, y_train)

    print("Model training complete.")
    print("----------------------------------------")


    # --- Step 6: Make Predictions and Evaluate the Model ---

    print("Step 6: Evaluating the Model")

    # Use the trained model to make predictions on the test data
    y_pred = model.predict(X_test)

    # 1. Accuracy
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Model Accuracy: {accuracy * 100:.2f}%")

    # 2. Confusion Matrix
    print("\nConfusion Matrix:")
    # A confusion matrix shows True Positives, False Positives,
    # True Negatives, and False Negatives.
    print(confusion_matrix(y_test, y_pred))

    # 3. Classification Report
    print("\nClassification Report:")
    # This shows precision, recall, and f1-score for each class.
    print(classification_report(y_test, y_pred))
    print("----------------------------------------")


    # --- Step 7: Visualize the Decision Tree ---

    print("Step 7: Visualizing the Decision Tree")
    print("Displaying the trained tree. This may take a moment...")

    # Get class names for the plot
    # If we used LabelEncoder, get names from it. Otherwise, use unique numbers.
    if 'le' in locals():
        class_names = le.classes_
    else:
        class_names = [str(c) for c in sorted(y.unique())]

    plt.figure(figsize=(20, 10))  # Set the figure size
    plot_tree(
        model,
        feature_names=X.columns,  # Names of all our feature columns
        class_names=class_names,  # Names of the target classes
        filled=True,              # Color the nodes
        rounded=True,             # Use rounded boxes
        fontsize=10
    )
    plt.title("Trained Decision Tree")
    plt.show()