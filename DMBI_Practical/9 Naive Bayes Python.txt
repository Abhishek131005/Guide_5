# --- Step 1: Import Libraries and Load Data ---

import pandas as pd
from google.colab import files
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.preprocessing import StandardScaler

# This line will open an "Upload" button for you to choose your file
print("Please upload your dataset (CSV file):")
uploaded = files.upload()

# Get the name of the file you just uploaded
file_name = list(uploaded.keys())[0]

# Read the CSV file into a pandas DataFrame
df = pd.read_csv(file_name)

print(f"\nSuccessfully loaded '{file_name}'")
print("----------------------------------------")


# --- Step 2: Data Inspection ---
# We look at the data to identify our features (X) and target (y).

print("Step 2: Data Inspection")
print("First 5 rows of the data:")
print(df.head())

print("\nColumn names and data types:")
df.info()
print("\nThis step is important to identify the TARGET column.")
print("----------------------------------------")


# --- Step 3: Data Preprocessing ---

print("Step 3: Data Preprocessing")

# !!! IMPORTANT: YOU MUST EDIT THIS LINE !!!
# Change 'YOUR_TARGET_COLUMN_NAME_HERE' to the actual name of your target column.
# This is the column you want to predict (e.g., 'Species', 'Purchased', 'Diagnosis').
TARGET_COLUMN = 'REPLACE WITH YOUR TARGET COLUMN'

# Check if the target column exists
if TARGET_COLUMN not in df.columns:
    print(f"Error: Target column '{TARGET_COLUMN}' not found in the dataset.")
    print("Please edit the 'TARGET_COLUMN' variable in the code.")
else:
    print(f"Target (y) column selected: {TARGET_COLUMN}")

    # --- 3a. Handle Missing Data (Simple) ---
    # Fill missing numerical data with the average (mean)
    for col in df.select_dtypes(include=['float64', 'int64']).columns:
        df[col] = df[col].fillna(df[col].mean())

    # Fill missing categorical (text) data with the most common value (mode)
    for col in df.select_dtypes(include=['object']).columns:
        df[col] = df[col].fillna(df[col].mode()[0])

    print("Missing data has been handled.")

    # --- 3b. Separate Features (X) and Target (y) ---
    X = df.drop(TARGET_COLUMN, axis=1)
    y = df[TARGET_COLUMN]

    # --- 3c. Encode Categorical Data ---
    # Convert all text feature columns (X) into numbers using One-Hot Encoding
    X = pd.get_dummies(X)
    print("Features (X) have been one-hot encoded.")

    # Convert the target column (y) into numbers using Label Encoding
    if y.dtype == 'object':
        le = LabelEncoder()
        y = le.fit_transform(y)
        print("Target (y) has been label encoded.")

    print("\nPreprocessed Features (X) - First 5 rows:")
    print(X.head())
    print("\nPreprocessed Target (y) - First 5 values:")
    # Check if y is a pandas Series before calling .head()
    if isinstance(y, pd.Series):
      print(y.head())
    else:
      # If y is a numpy array, print the first 5 elements
      print(y[:5])
    print("----------------------------------------")


    # --- Step 4: Split Data into Training and Testing Sets ---

    print("Step 4: Splitting data into Train and Test sets")
    # We use 70% of the data for training and 30% for testing
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    print(f"Training set size: {X_train.shape[0]} rows")
    print(f"Testing set size: {X_test.shape[0]} rows")
    print("----------------------------------------")


    # --- Step 5: Feature Scaling ---
    # Naive Bayes (especially GaussianNB) assumes features are normally
    # distributed. Scaling helps.

    print("Step 5: Feature Scaling")
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    print("Training and Test features have been scaled.")
    print("----------------------------------------")


    # --- Step 6: Build and Train the Naive Bayes Model ---

    print("Step 6: Building and Training the Naive Bayes Model")

    # Initialize the model. We use Gaussian Naive Bayes,
    # which assumes features follow a normal (bell-curve) distribution.
    model = GaussianNB()

    # Train the model on the training data
    model.fit(X_train, y_train)

    print("Model training complete.")
    print("----------------------------------------")


    # --- Step 7: Make Predictions and Evaluate the Model ---

    print("Step 7: Evaluating the Model")

    # Use the trained model to make predictions on the test data
    y_pred = model.predict(X_test)

    # 1. Accuracy
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Model Accuracy: {accuracy * 100:.2f}%")

    # 2. Confusion Matrix
    print("\nConfusion Matrix:")
    # A confusion matrix shows True Positives, False Positives,
    # True Negatives, and False Negatives.
    print(confusion_matrix(y_test, y_pred))

    # 3. Classification Report
    print("\nClassification Report:")
    # This shows precision, recall, and f1-score for each class.
    print(classification_report(y_test, y_pred))
    print("----------------------------------------")


    # --- Step 8: Note on Visualization ---
    print("Step 8: Visualization")
    print("Naive Bayes is a mathematical (probabilistic) model.")
    print("Unlike a Decision Tree, it does not create rules that")
    print("can be easily visualized as a tree.")
    print("Evaluation metrics (like accuracy) are the best way to")
    print("understand its performance.")
    print("----------------------------------------")